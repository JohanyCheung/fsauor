[back]
tf = 1.10.0
torch = 0.4.0
keras = 2.2.4

[segment]
tool = jieba
use_sep = yes

[random]
seed = 42
train_seed = 42
pre_seed = 16

[data]
train_download = data/ai_challenger_sentiment_analysis_trainingset_20180816/sentiment_analysis_trainingset.csv
val_download = data/ai_challenger_sentiment_analysis_validationset_20180816/sentiment_analysis_validationset.csv
testa_download = data/ai_challenger_sentiment_analysis_testa_20180816/sentiment_analysis_testa.csv
testb_download = data/ai_challenger_sentiment_analysis_testb_20180816/sentiment_analysis_testb.csv
train = preprocess/char/train_char.csv
val = preprocess/char/val_char.csv
testa = preprocess/char/testa_char.csv
testb = preprocess/char/testb_char.csv
src_field = content
fields = location_traffic_convenience,location_distance_from_business_district,location_easy_to_find,service_wait_time,service_waiters_attitude,service_parking_convenience,service_serving_speed,price_level,price_cost_effective,price_discount,environment_decoration,environment_noise,environment_space,environment_cleaness,dish_portion,dish_taste,dish_look,dish_recommendation,others_overall_experience,others_willing_to_consume_again
emoticon = ğŸ˜ƒğŸ˜„ğŸ˜ŠğŸ˜€ğŸ˜„ğŸ˜™ğŸ˜”ğŸ˜‚ğŸ˜­ğŸ¤‘ğŸ˜ğŸ˜ğŸ˜˜ğŸ˜ğŸ™„ğŸ˜…ğŸ˜‹ğŸ˜ğŸ˜ğŸ˜«ğŸ˜±ğŸ˜£ğŸ˜®ğŸ˜ğŸ˜¢ğŸ˜œğŸ˜›ğŸ˜ŒğŸŒğŸ˜“ğŸ˜¹ğŸ˜ğŸ‘ŒğŸ¤ğŸ’¯ğŸ®ğŸ¯â­ğŸŒŸğŸ¨ğŸ…¿ğŸš²ğŸ‘©ğŸ”ğŸ‰ğŸˆ¶ğŸšŒâœ¨âœŒğŸ»ğŸ£ğŸ‰ğŸ‘ğŸ‘âœ‹ğŸ‘‰â•ğŸ’“ğŸ’•ğŸ’–ğŸ’—ğŸ’™ğŸ’šğŸ’›ğŸ’œğŸ’ğŸ’ğŸ’Ÿâ£ğŸ’ŒğŸ‘„ğŸ‹ğŸ³ğŸ¬ğŸ¡ğŸŸğŸ ğŸ™ğŸ£â˜ğŸ”¥ğŸ²ğŸ®âƒ£ï¸ğŸ’ğŸŒƒğŸ²ğŸğŸ¼ğŸ‚ğŸ€ğŸŒ¿ğŸˆâ˜”ğŸŒ¹ğŸœâœğŸ’°ğŸ¹ğŸ’âŒâš¾ğŸºâ‹›â‹‹âŠ±Vâ‹ŒâŠ°â‹šÕÙ¼Õâ–¶â–²âˆ©oâ•¯â–¡â•°oï¸¶ï¸¿ï¸¶Øá–—Â¤Ì®Ì¤á–˜âŒ’`âˆ€ Ì â•­ï¿£â–½ï¿£â•®à¹‘à¸±à¹‡Ï‰ä¹›â—¡ä¹›á–˜â— â—¡ â— ï¾‰ â™¥3ã¥ã€€ â–‚.â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆï¼¼â‰ˆğŸ™ˆÏ€ã‚œğŸŒ¸ğŸ°â„ğŸ˜³ğŸ‰ğŸ˜¤ğŸ¤”ğŸŒ·ğŸğŸ‘»ğŸ’”ğŸ’ªğŸ˜—á›ğŸ¨ğŸ·ğŸ¼ğŸƒğŸšğŸ±ğŸ¶ğŸ»ğŸ¾ğŸ‘ˆğŸ’¨ğŸ“ğŸ“·ï‚²î—ê’«â“â™€â™‚â‘«â‘‰âŠ‚âƒ•âƒ”â€–á´¥á†ºàª¿à±ªğŸŠğŸ—ğŸ¸ğŸ»ğŸ„ğŸ†ğŸ½ğŸŒğŸ‘³ğŸ™‹ğŸ™†ğŸ˜¯ğŸ˜ğŸ’¢ğŸ‘¬ğŸ‘¦ğŸ‘‡ğŸ°ğŸğŸ„ğŸƒğŸŒ¶ğŸŒ®â‰§â‰¦

[embedding]
char2vec = word2vec/chars.vector
word2vec = word2vec/words.vector
pinyin2vec = word2vec/pinyin.vector
stroke2vec = word2vec/stroke.vector
size = 100
window = 5

[label]
vocab = -2,-1,0,1